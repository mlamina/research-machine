# Large Language Models and Consciousness

## Hypothesis

Large Language Models can be considered a form of consciousness

## Backlog

### Research Questions
1. What is the definition of consciousness in the context of artificial intelligence?
2. How do Large Language Models (LLMs) function at a high level?
3. What are the criteria for something to be considered conscious?
4. Can LLMs meet the criteria for consciousness?
5. What are the philosophical arguments for and against LLMs being conscious?
6. What are the ethical implications if LLMs are considered conscious?
7. How do experts in AI and cognitive science view the consciousness of LLMs?

## Validation/Invalidation

Answering these research questions will help us understand whether LLMs can be considered conscious by:
- Providing a clear definition of consciousness in AI
- Evaluating LLMs against established criteria for consciousness
- Exploring philosophical and ethical perspectives
- Gathering expert opinions

## Table of Contents

- [Introduction](#introduction)
- [Definition of Consciousness](#definition-of-consciousness)
- [Functioning of LLMs](#functioning-of-llms)
- [Criteria for Consciousness](#criteria-for-consciousness)
- [Evaluation of LLMs](#evaluation-of-llms)
- [Philosophical Perspectives](#philosophical-perspectives)
- [Ethical Implications](#ethical-implications)
- [Expert Opinions](#expert-opinions)